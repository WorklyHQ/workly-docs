# ğŸ—ï¸ Architecture Modules IA - Session 14

**Date** : 16 novembre 2025
**Version** : 0.18.0-alpha (cible)

---

## ğŸ“Š Vue d'Ensemble

Cette architecture dÃ©crit comment les 6 nouveaux modules IA s'intÃ¨grent avec le systÃ¨me existant.

### Diagramme GÃ©nÃ©ral

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Application Qt (app.py)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ChatEngine (Orchestrateur)                    â”‚
â”‚  - GÃ¨re conversation principale                                 â”‚
â”‚  - Coordonne tous les modules IA                                â”‚
â”‚  - GÃ©nÃ¨re rÃ©ponses utilisateur                                  â”‚
â””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚           â”‚           â”‚           â”‚           â”‚
  â–¼           â–¼           â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Memory â”‚ â”‚Persona â”‚ â”‚Emotion   â”‚ â”‚Context â”‚ â”‚Model     â”‚
â”‚Managerâ”‚ â”‚lity    â”‚ â”‚Analyzer  â”‚ â”‚Analyzerâ”‚ â”‚Manager   â”‚
â”‚       â”‚ â”‚Engine  â”‚ â”‚          â”‚ â”‚        â”‚ â”‚          â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚         â”‚           â”‚            â”‚
    â–¼         â–¼           â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  (Pas de sous-module)
â”‚Conv.  â”‚ â”‚Traitsâ”‚  â”‚Emotion   â”‚
â”‚Summ.  â”‚ â”‚Dict  â”‚  â”‚Memory    â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚Fact   â”‚
â”‚Extractâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Modules DÃ©taillÃ©s

### 1ï¸âƒ£ MemoryManager (Nouveau)

**Fichier** : `src/ai/memory_manager.py`
**Lignes estimÃ©es** : ~400

**ResponsabilitÃ©s** :
- Stockage/rÃ©cupÃ©ration mÃ©moire long-terme
- Recherche sÃ©mantique dans historique
- Coordination rÃ©sumÃ©s et extraction faits
- Gestion persistance fichiers JSON

**Classe Principale** :

```python
class MemoryManager:
    """Gestionnaire mÃ©moire long-terme de l'assistant."""

    def __init__(self, storage_path: str = "data/memory/"):
        self.storage_path = storage_path
        self.summarizer = ConversationSummarizer()
        self.fact_extractor = FactExtractor()
        self.embeddings_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.conversations: List[ConversationSummary] = []
        self.facts: Dict[str, Any] = {}
        self._load_memory()

    # MÃ©thodes publiques
    def store_message(self, message: str, role: str, metadata: dict) -> None
    def get_relevant_context(self, query: str, k: int = 5) -> List[str]
    def summarize_if_needed(self, force: bool = False) -> Optional[str]
    def extract_facts(self, messages: List[dict]) -> Dict[str, Any]
    def search_by_topic(self, topic: str, k: int = 3) -> List[str]

    # MÃ©thodes privÃ©es
    def _load_memory(self) -> None
    def _save_conversations(self) -> None
    def _save_facts(self) -> None
    def _save_embeddings(self) -> None
    def _compute_embedding(self, text: str) -> np.ndarray
    def _cosine_similarity(self, a: np.ndarray, b: np.ndarray) -> float
```

**DÃ©pendances** :
- `ConversationSummarizer` (rÃ©sumÃ©s)
- `FactExtractor` (extraction faits)
- `sentence-transformers` (embeddings)
- `numpy` (cosine similarity)

**Stockage** :
- `data/memory/conversations.json` : RÃ©sumÃ©s conversations
- `data/memory/facts.json` : Faits extraits
- `data/memory/embeddings.json` : Vecteurs embeddings

---

### 2ï¸âƒ£ ConversationSummarizer (Nouveau)

**Fichier** : `src/ai/conversation_summarizer.py`
**Lignes estimÃ©es** : ~200

**ResponsabilitÃ©s** :
- GÃ©nÃ©rer rÃ©sumÃ©s conversations via LLM
- DÃ©tecter points clÃ©s importants
- Compression intelligente contexte

**Classe Principale** :

```python
class ConversationSummarizer:
    """GÃ©nÃ¨re rÃ©sumÃ©s de conversations."""

    def __init__(self, model_manager):
        self.model_manager = model_manager
        self.summary_prompt_template = """RÃ©sume la conversation suivante en 2-3 phrases.
Garde les informations importantes (nom, prÃ©fÃ©rences, sujets principaux).

Conversation:
{conversation}

RÃ©sumÃ©:"""

    # MÃ©thodes publiques
    def summarize(self, messages: List[dict], max_tokens: int = 150) -> str
    def detect_key_points(self, messages: List[dict]) -> List[str]
    def should_summarize(self, message_count: int, threshold: int = 20) -> bool

    # MÃ©thodes privÃ©es
    def _format_conversation(self, messages: List[dict]) -> str
    def _extract_key_sentences(self, text: str, top_k: int = 3) -> List[str]
```

**DÃ©pendances** :
- `ModelManager` (accÃ¨s Zephyr-7B)
- Prompts spÃ©cialisÃ©s rÃ©sumÃ©

**Logique RÃ©sumÃ©** :
1. Trigger : AprÃ¨s 20-30 messages
2. Format : 2-3 phrases concises
3. Stocke : RÃ©sumÃ© + timestamp + IDs messages originaux

---

### 3ï¸âƒ£ FactExtractor (Nouveau)

**Fichier** : `src/ai/fact_extractor.py`
**Lignes estimÃ©es** : ~250

**ResponsabilitÃ©s** :
- Extraire entitÃ©s (nom, lieux, dates)
- DÃ©tecter prÃ©fÃ©rences utilisateur
- Identifier Ã©vÃ©nements marquants
- Extraire relations entre entitÃ©s

**Classe Principale** :

```python
class FactExtractor:
    """Extrait faits importants des conversations."""

    def __init__(self):
        # Patterns regex pour extraction basique
        self.name_patterns = [
            r"je m'appelle (\w+)",
            r"mon nom est (\w+)",
            r"appelle[-\s]moi (\w+)",
        ]
        self.preference_keywords = [
            "j'aime", "je prÃ©fÃ¨re", "je dÃ©teste", "je n'aime pas",
            "mon favori", "ma passion", "j'adore"
        ]

    # MÃ©thodes publiques
    def extract_entities(self, text: str) -> Dict[str, List[str]]
    def extract_preferences(self, text: str) -> List[Preference]
    def extract_events(self, text: str) -> List[Event]
    def extract_relationships(self, entities: List[str]) -> List[Relationship]
    def extract_all_facts(self, messages: List[dict]) -> Dict[str, Any]

    # MÃ©thodes privÃ©es
    def _extract_name(self, text: str) -> Optional[str]
    def _extract_dates(self, text: str) -> List[str]
    def _extract_locations(self, text: str) -> List[str]
    def _detect_preference_context(self, text: str) -> Optional[dict]
```

**Types Faits Extraits** :

```python
@dataclass
class Preference:
    category: str  # ex: "musique", "nourriture", "activitÃ©"
    item: str      # ex: "jazz", "pizza", "course"
    sentiment: str # "positive" ou "negative"
    confidence: float

@dataclass
class Event:
    description: str
    timestamp: Optional[datetime]
    importance: float  # 0.0-1.0

@dataclass
class Relationship:
    entity_1: str
    relation_type: str
    entity_2: str
```

**MÃ©thodes Extraction** :
1. **Regex** : Patterns simples (nom, dates)
2. **Keywords** : PrÃ©fÃ©rences explicites
3. **LLM** : Faits complexes (optionnel si temps calcul OK)

---

### 4ï¸âƒ£ PersonalityEngine (Nouveau)

**Fichier** : `src/ai/personality_engine.py`
**Lignes estimÃ©es** : ~350

**ResponsabilitÃ©s** :
- GÃ©rer traits personnalitÃ© (5-7 traits)
- GÃ©nÃ©rer prompts systÃ¨me adaptatifs
- Faire Ã©voluer personnalitÃ© selon interactions
- Garantir cohÃ©rence long-terme

**Classe Principale** :

```python
class PersonalityEngine:
    """Moteur personnalitÃ© Ã©volutive."""

    def __init__(self, storage_path: str = "data/personality.json"):
        self.storage_path = storage_path
        self.traits: Dict[str, float] = {
            "extraversion": 0.6,   # 0.0=introverti, 1.0=extraverti
            "empathie": 0.8,       # 0.0=rationnel, 1.0=empathique
            "humour": 0.5,         # 0.0=sÃ©rieux, 1.0=blagueur
            "formalitÃ©": 0.3,      # 0.0=casual, 1.0=formel
            "curiositÃ©": 0.7,      # 0.0=passif, 1.0=curieux
            "enthousiasme": 0.6,   # 0.0=calme, 1.0=Ã©nergique
            "patience": 0.7,       # 0.0=impatient, 1.0=patient
        }
        self.history: List[TraitUpdate] = []
        self._load_personality()

    # MÃ©thodes publiques
    def generate_system_prompt(self) -> str
    def update_traits(self, interaction_data: dict) -> Dict[str, float]
    def get_response_style(self) -> dict
    def should_ask_followup(self) -> bool
    def get_trait_description(self) -> str

    # MÃ©thodes privÃ©es
    def _load_personality(self) -> None
    def _save_personality(self) -> None
    def _compute_trait_change(self, feedback: str, trait: str) -> float
    def _ensure_coherence(self) -> None
    def _generate_trait_modifiers(self) -> dict
```

**GÃ©nÃ©ration Prompts Exemples** :

```python
# Extraversion=0.8, Empathie=0.9, Humour=0.6
"Tu es Kira, une assistante virtuelle trÃ¨s bavarde et profondÃ©ment empathique.
Tu adores engager la conversation, poser des questions, et montrer une grande
sensibilitÃ© aux Ã©motions. Tu utilises occasionnellement l'humour pour dÃ©tendre."

# Extraversion=0.3, Empathie=0.5, FormalitÃ©=0.8
"Tu es Kira, une assistante virtuelle concise et professionnelle.
Tu privilÃ©gies les rÃ©ponses courtes et factuelles, avec un ton formel.
Tu restes neutre Ã©motionnellement et vas droit au but."
```

**Ã‰volution Traits** :
- Feedback positif â†’ Renforce trait utilisÃ©
- Feedback nÃ©gatif â†’ AttÃ©nue trait
- Changement graduel (max Â±0.05 par interaction)
- VÃ©rification cohÃ©rence (pas de contradictions extrÃªmes)

---

### 5ï¸âƒ£ EmotionAnalyzer (AmÃ©lioration Existant)

**Fichier** : `src/ai/emotion_analyzer.py`
**Lignes actuelles** : ~300 â†’ **Cible : ~500**

**ResponsabilitÃ©s** :
- Analyser Ã©motions avec contexte (pas seulement keywords)
- GÃ©rer transitions Ã©motionnelles douces
- IntÃ©grer mÃ©moire Ã©motionnelle
- DÃ©tecter Ã©motions composÃ©es

**Classe ModifiÃ©e** :

```python
class EmotionAnalyzer:
    """Analyseur Ã©motions avancÃ© avec contexte."""

    def __init__(self):
        # Ã‰motions existantes
        self.emotions = ["neutre", "joyeux", "triste", "surpris",
                        "Ã©nervÃ©", "pensif", "timide"]
        # Nouvelles Ã©motions composÃ©es
        self.compound_emotions = {
            "excitÃ©": ("joyeux", "surpris", 0.6, 0.4),
            "frustrÃ©": ("Ã©nervÃ©", "triste", 0.7, 0.3),
            "mÃ©lancolique": ("triste", "pensif", 0.5, 0.5),
            "confiant": ("neutre", "joyeux", 0.6, 0.4),
            "anxieux": ("timide", "Ã©nervÃ©", 0.6, 0.4),
        }
        self.emotion_memory = EmotionMemory()
        self.keywords = {...}  # Existant

    # MÃ©thodes publiques (nouvelles/modifiÃ©es)
    def analyze_emotion(self, text: str, context: List[str] = None) -> Tuple[str, float]
    def analyze_with_context(self, text: str, previous_emotion: str,
                            previous_intensity: float) -> Tuple[str, float]
    def detect_emotion_llm(self, text: str) -> Tuple[str, float]
    def blend_emotions(self, emotion1: str, intensity1: float,
                      emotion2: str, intensity2: float,
                      blend_factor: float = 0.3) -> Tuple[str, float]
    def should_transition(self, new_emotion: str, new_intensity: float) -> bool

    # MÃ©thodes existantes (garder)
    def _analyze_keywords(self, text: str) -> Tuple[str, float]
    def _get_emotion_from_intensity(self, scores: dict) -> Tuple[str, float]
```

**AmÃ©liorations** :
1. **Analyse contextuelle** : Prend en compte messages prÃ©cÃ©dents
2. **LLM-based** (optionnel) : DÃ©tection Ã©motions complexes via Zephyr
3. **Transitions douces** : Blend entre Ã©motion actuelle et nouvelle
4. **MÃ©moire Ã©motionnelle** : Se souvient Ã©tats prÃ©cÃ©dents

**Formule Transition** :

```python
# Ã‰viter changements brusques
if abs(new_intensity - previous_intensity) > 0.4:
    # Transition douce sur 2-3 rÃ©ponses
    blended_intensity = previous_intensity * 0.7 + new_intensity * 0.3
```

---

### 6ï¸âƒ£ EmotionMemory (Nouveau)

**Fichier** : `src/ai/emotion_memory.py`
**Lignes estimÃ©es** : ~200

**ResponsabilitÃ©s** :
- Stocker historique Ã©motions (100 derniÃ¨res)
- Analyser tendances Ã©motionnelles
- Valider transitions rÃ©alistes
- DÃ©tecter patterns Ã©motionnels

**Classe Principale** :

```python
class EmotionMemory:
    """MÃ©moire Ã©motionnelle pour transitions rÃ©alistes."""

    def __init__(self, storage_path: str = "data/emotion_history.json"):
        self.storage_path = storage_path
        self.history: Deque[EmotionEntry] = deque(maxlen=100)
        self._load_history()

    # MÃ©thodes publiques
    def add_emotion(self, emotion: str, intensity: float, context: str) -> None
    def get_recent_emotions(self, window: int = 10) -> List[EmotionEntry]
    def get_dominant_emotion(self, window: int = 10) -> Tuple[str, float]
    def get_emotional_trend(self) -> str  # "stable", "ascending", "descending"
    def should_allow_transition(self, current: str, new: str) -> bool
    def get_transition_probability(self, from_emotion: str,
                                   to_emotion: str) -> float

    # MÃ©thodes privÃ©es
    def _load_history(self) -> None
    def _save_history(self) -> None
    def _compute_trend(self, intensities: List[float]) -> str
    def _get_transition_matrix(self) -> Dict[str, Dict[str, float]]
```

**EmotionEntry** :

```python
@dataclass
class EmotionEntry:
    emotion: str
    intensity: float
    timestamp: datetime
    context: str  # Court rÃ©sumÃ© pourquoi cette Ã©motion
```

**Matrice Transitions** (exemple) :

```python
# ProbabilitÃ©s transitions Ã©motionnelles rÃ©alistes
{
    "joyeux": {"joyeux": 0.6, "neutre": 0.2, "surpris": 0.15, "triste": 0.05},
    "triste": {"triste": 0.5, "neutre": 0.3, "joyeux": 0.1, "Ã©nervÃ©": 0.1},
    "Ã©nervÃ©": {"Ã©nervÃ©": 0.4, "neutre": 0.3, "triste": 0.2, "joyeux": 0.1},
    # ... etc pour toutes Ã©motions
}
```

---

### 7ï¸âƒ£ ContextAnalyzer (Nouveau)

**Fichier** : `src/ai/context_analyzer.py`
**Lignes estimÃ©es** : ~300

**ResponsabilitÃ©s** :
- DÃ©tecter intentions utilisateur
- Analyser sentiment global message
- SuggÃ©rer actions proactives
- Identifier sujets de conversation

**Classe Principale** :

```python
class ContextAnalyzer:
    """Analyseur contextuel avancÃ©."""

    def __init__(self):
        self.intents = [
            "question",
            "demande_action",
            "conversation_casual",
            "plainte",
            "remerciement",
            "salutation",
            "au_revoir",
            "feedback",
        ]
        self.intent_keywords = {...}  # Patterns par intent

    # MÃ©thodes publiques
    def detect_intent(self, message: str) -> Tuple[str, float]
    def analyze_sentiment(self, message: str) -> Tuple[str, float]  # positif/nÃ©gatif/neutre
    def extract_topic(self, message: str) -> Optional[str]
    def should_ask_followup(self, conversation_history: List[dict]) -> bool
    def generate_proactive_suggestion(self, context: dict) -> Optional[str]
    def detect_question_type(self, message: str) -> str  # "comment", "pourquoi", "quoi", etc.

    # MÃ©thodes privÃ©es
    def _match_intent_keywords(self, message: str) -> Dict[str, float]
    def _analyze_sentence_structure(self, message: str) -> dict
    def _compute_sentiment_score(self, message: str) -> float
    def _extract_action_verbs(self, message: str) -> List[str]
```

**Exemples DÃ©tections** :

```python
# Input: "Comment crÃ©er un rappel ?"
â†’ Intent: "question" (0.95)
â†’ Topic: "features_app"
â†’ Question type: "comment"
â†’ Suggestion: Afficher exemple commande rappel

# Input: "J'en ai marre de ce projet"
â†’ Intent: "plainte" (0.90)
â†’ Sentiment: nÃ©gatif (-0.7)
â†’ Topic: "projet"
â†’ Suggestion: Proposer pause ou aide

# Input: "Merci pour ton aide !"
â†’ Intent: "remerciement" (1.0)
â†’ Sentiment: positif (0.9)
â†’ Suggestion: Offrir aide future
```

---

## ğŸ”„ IntÃ©gration avec ChatEngine

**Fichier** : `src/ai/chat_engine.py` (Ã  modifier)

### Modifications Principales

```python
class ChatEngine:
    def __init__(self, model_manager):
        self.model_manager = model_manager

        # Modules existants
        self.emotion_analyzer = EmotionAnalyzer()
        self.conversation_history = []

        # NOUVEAUX modules
        self.memory_manager = MemoryManager()
        self.personality_engine = PersonalityEngine()
        self.context_analyzer = ContextAnalyzer()

        # Ã‰tat actuel
        self.current_emotion = "neutre"
        self.current_intensity = 0.5

    def generate_response(self, user_message: str) -> dict:
        """GÃ©nÃ¨re rÃ©ponse avec tous modules IA activÃ©s."""

        # 1. Analyse contextuelle
        intent, intent_conf = self.context_analyzer.detect_intent(user_message)
        sentiment, sent_conf = self.context_analyzer.analyze_sentiment(user_message)

        # 2. RÃ©cupÃ©ration contexte mÃ©moire long-terme
        relevant_context = self.memory_manager.get_relevant_context(user_message, k=3)

        # 3. GÃ©nÃ©ration prompt systÃ¨me adaptatif (personnalitÃ©)
        system_prompt = self.personality_engine.generate_system_prompt()

        # 4. Construction prompt avec contexte
        full_context = self._build_context(
            user_message,
            relevant_context,
            self.conversation_history[-10:],  # Court-terme
        )

        # 5. GÃ©nÃ©ration rÃ©ponse LLM
        response = self.model_manager.generate(
            prompt=full_context,
            system_prompt=system_prompt,
        )

        # 6. Analyse Ã©motion rÃ©ponse (avec contexte prÃ©cÃ©dent)
        emotion, intensity = self.emotion_analyzer.analyze_with_context(
            response,
            self.current_emotion,
            self.current_intensity,
        )

        # 7. Stockage mÃ©moire
        self.memory_manager.store_message(
            user_message,
            role="user",
            metadata={"intent": intent, "sentiment": sentiment}
        )
        self.memory_manager.store_message(
            response,
            role="assistant",
            metadata={"emotion": emotion, "intensity": intensity}
        )

        # 8. RÃ©sumÃ© si nÃ©cessaire
        summary = self.memory_manager.summarize_if_needed()

        # 9. Mise Ã  jour personnalitÃ©
        self.personality_engine.update_traits({
            "user_message": user_message,
            "intent": intent,
            "sentiment": sentiment,
        })

        # 10. Mise Ã  jour Ã©tat Ã©motionnel
        self.current_emotion = emotion
        self.current_intensity = intensity

        return {
            "response": response,
            "emotion": emotion,
            "intensity": intensity,
            "intent": intent,
            "summary_generated": summary is not None,
        }
```

---

## ğŸ“Š Flux de DonnÃ©es

### ScÃ©nario : Utilisateur envoie message

```
1. USER â†’ "Comment vas-tu ?"
         â”‚
         â–¼
2. ContextAnalyzer.detect_intent()
   â†’ intent = "question", confidence = 0.95
   â†’ sentiment = "neutre", confidence = 0.8
         â”‚
         â–¼
3. MemoryManager.get_relevant_context("Comment vas-tu ?", k=3)
   â†’ Recherche sÃ©mantique dans conversations passÃ©es
   â†’ Retourne : ["User a demandÃ© comment je vais hier", ...]
         â”‚
         â–¼
4. PersonalityEngine.generate_system_prompt()
   â†’ GÃ©nÃ¨re prompt selon traits actuels (extraversion=0.7, empathie=0.8)
   â†’ "Tu es Kira, bavarde et empathique..."
         â”‚
         â–¼
5. ChatEngine._build_context()
   â†’ Combine : system_prompt + contexte long-terme + historique court-terme
         â”‚
         â–¼
6. ModelManager.generate()
   â†’ Zephyr-7B gÃ©nÃ¨re : "Je vais trÃ¨s bien merci ! Et toi ?"
         â”‚
         â–¼
7. EmotionAnalyzer.analyze_with_context()
   â†’ DÃ©tecte : emotion="joyeux", intensity=0.7
   â†’ VÃ©rifie transition OK (prÃ©cÃ©dent: neutre â†’ joyeux = OK)
         â”‚
         â–¼
8. MemoryManager.store_message() Ã— 2
   â†’ Stocke message user + metadata (intent, sentiment)
   â†’ Stocke rÃ©ponse assistant + metadata (emotion, intensity)
         â”‚
         â–¼
9. MemoryManager.summarize_if_needed()
   â†’ Compte messages : 25 â†’ Trigger rÃ©sumÃ©
   â†’ ConversationSummarizer.summarize() via LLM
   â†’ Stocke rÃ©sumÃ© dans data/memory/conversations.json
         â”‚
         â–¼
10. PersonalityEngine.update_traits()
    â†’ Analyse interaction : intent=question, sentiment=neutre
    â†’ Ajuste lÃ©gÃ¨rement : curiositÃ© +0.02, empathie +0.01
         â”‚
         â–¼
11. RETURN â†’ {"response": "...", "emotion": "joyeux", ...}
    â†’ EnvoyÃ© Ã  Unity pour affichage blendshape
    â†’ AffichÃ© dans GUI Qt
```

---

## ğŸ§ª Tests Unitaires

### Structure Tests

```
tests/ai/
â”œâ”€â”€ test_memory_manager.py
â”œâ”€â”€ test_conversation_summarizer.py
â”œâ”€â”€ test_fact_extractor.py
â”œâ”€â”€ test_personality_engine.py
â”œâ”€â”€ test_emotion_analyzer.py (existant, Ã  Ã©tendre)
â”œâ”€â”€ test_emotion_memory.py
â”œâ”€â”€ test_context_analyzer.py
â””â”€â”€ test_integration_chatengine.py (nouveau)
```

### Fixtures Pytest

```python
# tests/ai/conftest.py
import pytest
from src.ai.memory_manager import MemoryManager
from src.ai.personality_engine import PersonalityEngine

@pytest.fixture
def temp_storage(tmp_path):
    """Dossier temporaire pour tests."""
    return str(tmp_path)

@pytest.fixture
def memory_manager(temp_storage):
    """MemoryManager avec stockage temporaire."""
    return MemoryManager(storage_path=temp_storage)

@pytest.fixture
def personality_engine(temp_storage):
    """PersonalityEngine avec stockage temporaire."""
    storage = f"{temp_storage}/personality.json"
    return PersonalityEngine(storage_path=storage)

@pytest.fixture
def sample_conversation():
    """Conversation type pour tests."""
    return [
        {"role": "user", "content": "Bonjour, je m'appelle Alice"},
        {"role": "assistant", "content": "Bonjour Alice ! EnchantÃ©e !"},
        {"role": "user", "content": "J'aime beaucoup la musique jazz"},
        {"role": "assistant", "content": "Le jazz c'est magnifique !"},
    ]
```

---

## âš ï¸ ConsidÃ©rations Performance

### VRAM (GPU)

**Budget strict** : RTX 4050 6GB VRAM

```
Zephyr-7B (profil performance) : 5.0-5.5 GB
Embeddings all-MiniLM-L6-v2    : ~80 MB (RAM, pas VRAM)
Marge disponible               : ~500 MB
```

**Pas de risque saturation VRAM** : Les embeddings sentence-transformers tournent sur CPU par dÃ©faut.

### RAM

**Budget** : 16 GB total (Windows + Unity + Python)

```
Windows 11                  : ~4 GB
Unity (avatar VRM)          : ~1.5 GB
Python app + PySide6        : ~500 MB
Zephyr-7B (hors VRAM)       : ~500 MB
Embeddings model            : ~150 MB
Memory data (conversations) : ~50-100 MB
Marge                       : ~9 GB disponibles
```

**OK** : Largement suffisant.

### Temps RÃ©ponse

**Objectif** : <3s par rÃ©ponse (avec tous modules)

**DÃ©composition estimÃ©e** :

```
ContextAnalyzer.detect_intent()       : ~10 ms
MemoryManager.get_relevant_context()  : ~50 ms (recherche embeddings)
PersonalityEngine.generate_prompt()   : ~5 ms
ModelManager.generate() (Zephyr)      : ~2000 ms (CUDA)
EmotionAnalyzer.analyze_with_context(): ~20 ms
MemoryManager.store_message()         : ~10 ms
PersonalityEngine.update_traits()     : ~5 ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL                                 : ~2100 ms = 2.1s
```

**âœ… Objectif atteint** : <3s

**Optimisations possibles** :
- Recherche embeddings async (parallÃ¨le gÃ©nÃ©ration LLM)
- Cache rÃ©sultats ContextAnalyzer si message similaire
- Batch updates PersonalityEngine (tous les 5-10 messages)

---

## ğŸ”’ Gestion Erreurs

### StratÃ©gies Robustesse

**MemoryManager** :
- Fichier JSON corrompu â†’ Backup + recrÃ©er
- Embeddings manquants â†’ Recalculer Ã  la demande
- Disk full â†’ Purge anciennes conversations (>6 mois)

**ConversationSummarizer** :
- LLM timeout â†’ Utiliser rÃ©sumÃ© basique (premiers/derniers messages)
- RÃ©sumÃ© incohÃ©rent â†’ Retry avec prompt modifiÃ©

**PersonalityEngine** :
- Traits incohÃ©rents â†’ Reset valeurs par dÃ©faut
- Ã‰volution trop rapide â†’ Limiter changements (max Â±0.05/interaction)

**EmotionAnalyzer** :
- Ã‰motion inconnue â†’ Fallback "neutre"
- Transition invalide â†’ Forcer blend progressif

**ContextAnalyzer** :
- Intent incertain â†’ Utiliser "conversation_casual" par dÃ©faut
- Sentiment ambigu â†’ "neutre" avec confidence faible

---

## ğŸ“ Prochaines Ã‰tapes

âœ… Architecture documentÃ©e
ğŸš§ Structures JSON Ã  dÃ©finir â†’ **DATA_SCHEMAS.md**
ğŸš§ Guide intÃ©gration ChatEngine â†’ **INTEGRATION_GUIDE.md**
ğŸš§ StratÃ©gie tests dÃ©taillÃ©e â†’ **TESTING_STRATEGY.md**
ğŸš§ Plan phases dÃ©veloppement â†’ **DEVELOPMENT_PHASES.md**

---

**CrÃ©Ã© le** : 16 novembre 2025
**DerniÃ¨re mise Ã  jour** : 16 novembre 2025
