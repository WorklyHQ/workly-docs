# ğŸ”Œ Guide IntÃ©gration ChatEngine - Session 14

**Date** : 16 novembre 2025
**Version** : 0.18.0-alpha (cible)

---

## ğŸ¯ Objectif

Ce guide dÃ©taille **comment intÃ©grer** les 6 nouveaux modules IA avec le `ChatEngine` existant, en minimisant les modifications du code actuel et en garantissant la rÃ©trocompatibilitÃ©.

---

## ğŸ“Š Ã‰tat Actuel ChatEngine

**Fichier** : `src/ai/chat_engine.py` (~400 lignes)

### Structure Actuelle

```python
class ChatEngine:
    def __init__(self, model_manager):
        self.model_manager = model_manager
        self.emotion_analyzer = EmotionAnalyzer()
        self.conversation_history = []  # Limite 10 messages
        self.system_prompt = "Tu es Kira, une assistante virtuelle amicale et empathique..."

    def generate_response(self, user_message: str) -> dict:
        # 1. Ajouter message Ã  historique
        self.conversation_history.append({"role": "user", "content": user_message})

        # 2. Construire contexte (10 derniers messages)
        context = self._build_context()

        # 3. GÃ©nÃ©rer rÃ©ponse via LLM
        response = self.model_manager.generate(context, system_prompt=self.system_prompt)

        # 4. DÃ©tecter Ã©motion (keywords)
        emotion, intensity = self.emotion_analyzer.analyze_emotion(response)

        # 5. Ajouter rÃ©ponse Ã  historique
        self.conversation_history.append({"role": "assistant", "content": response})

        # 6. Limiter historique Ã  10 messages
        if len(self.conversation_history) > 10:
            self.conversation_history = self.conversation_history[-10:]

        return {
            "response": response,
            "emotion": emotion,
            "intensity": intensity
        }
```

---

## ğŸ”§ Modifications NÃ©cessaires

### Ã‰tape 1 : Ajouter Imports

**Fichier** : `src/ai/chat_engine.py` (dÃ©but fichier)

```python
# Imports existants
from typing import List, Dict, Any, Optional, Tuple
import logging

# NOUVEAUX imports
from src.ai.memory_manager import MemoryManager
from src.ai.personality_engine import PersonalityEngine
from src.ai.emotion_memory import EmotionMemory
from src.ai.context_analyzer import ContextAnalyzer

logger = logging.getLogger(__name__)
```

---

### Ã‰tape 2 : Modifier __init__()

**Avant** :

```python
def __init__(self, model_manager):
    self.model_manager = model_manager
    self.emotion_analyzer = EmotionAnalyzer()
    self.conversation_history = []
    self.system_prompt = "Tu es Kira, une assistante virtuelle amicale et empathique..."
```

**AprÃ¨s** :

```python
def __init__(self, model_manager, enable_advanced_ai: bool = True):
    """
    Initialise le ChatEngine.

    Args:
        model_manager: Gestionnaire modÃ¨le LLM
        enable_advanced_ai: Activer modules IA avancÃ©s (dÃ©faut: True)
    """
    self.model_manager = model_manager
    self.enable_advanced_ai = enable_advanced_ai

    # Module Ã©motions (AMÃ‰LIORER existant)
    self.emotion_analyzer = EmotionAnalyzer()

    # Ã‰tat Ã©motionnel actuel
    self.current_emotion = "neutre"
    self.current_intensity = 0.5

    # Historique court-terme (garder pour compatibilitÃ©)
    self.conversation_history = []

    # NOUVEAUX modules IA (si activÃ©s)
    if self.enable_advanced_ai:
        logger.info("ğŸ§  Initialisation modules IA avancÃ©s...")

        self.memory_manager = MemoryManager(storage_path="data/memory/")
        self.personality_engine = PersonalityEngine(storage_path="data/personality.json")
        self.context_analyzer = ContextAnalyzer()

        # EmotionMemory utilisÃ© par EmotionAnalyzer amÃ©liorÃ©
        self.emotion_analyzer.emotion_memory = EmotionMemory(storage_path="data/emotion_history.json")

        logger.info("âœ… Modules IA avancÃ©s prÃªts !")
    else:
        logger.info("âš ï¸ Modules IA avancÃ©s dÃ©sactivÃ©s (mode legacy)")
        self.memory_manager = None
        self.personality_engine = None
        self.context_analyzer = None

    # Prompt systÃ¨me (sera remplacÃ© dynamiquement si PersonalityEngine activÃ©)
    self.base_system_prompt = "Tu es Kira, une assistante virtuelle amicale et empathique."
```

**Raisons** :
- âœ… RÃ©trocompatibilitÃ© : `enable_advanced_ai=False` dÃ©sactive nouveaux modules
- âœ… Logs clairs : Utilisateur sait si modules actifs
- âœ… Ã‰tat Ã©motionnel : Suivi Ã©motion courante pour transitions douces

---

### Ã‰tape 3 : Modifier generate_response() (CRITIQUE)

**Structure Nouvelle** :

```python
def generate_response(self, user_message: str) -> dict:
    """
    GÃ©nÃ¨re rÃ©ponse avec tous modules IA activÃ©s.

    Args:
        user_message: Message utilisateur

    Returns:
        dict avec response, emotion, intensity, metadata
    """
    logger.debug(f"ğŸ“© Message utilisateur: {user_message[:50]}...")

    # === PHASE 1: ANALYSE CONTEXTUELLE ===
    intent, intent_conf = None, 0.0
    sentiment, sent_score = None, 0.0

    if self.enable_advanced_ai and self.context_analyzer:
        intent, intent_conf = self.context_analyzer.detect_intent(user_message)
        sentiment, sent_score = self.context_analyzer.analyze_sentiment(user_message)
        logger.debug(f"ğŸ” Intent: {intent} ({intent_conf:.2f}), Sentiment: {sentiment} ({sent_score:.2f})")

    # === PHASE 2: RÃ‰CUPÃ‰RATION MÃ‰MOIRE LONG-TERME ===
    relevant_context = []

    if self.enable_advanced_ai and self.memory_manager:
        relevant_context = self.memory_manager.get_relevant_context(user_message, k=3)
        logger.debug(f"ğŸ§  Contexte pertinent: {len(relevant_context)} entrÃ©es")

    # === PHASE 3: GÃ‰NÃ‰RATION PROMPT SYSTÃˆME ADAPTATIF ===
    system_prompt = self.base_system_prompt

    if self.enable_advanced_ai and self.personality_engine:
        system_prompt = self.personality_engine.generate_system_prompt()
        logger.debug(f"ğŸ­ Prompt systÃ¨me adaptatif gÃ©nÃ©rÃ©")

    # === PHASE 4: CONSTRUCTION CONTEXTE COMPLET ===
    full_context = self._build_full_context(
        user_message=user_message,
        relevant_memory=relevant_context,
        short_term_history=self.conversation_history[-10:],  # Garder 10 derniers
    )

    # === PHASE 5: GÃ‰NÃ‰RATION RÃ‰PONSE LLM ===
    logger.debug("ğŸ’¬ GÃ©nÃ©ration rÃ©ponse LLM...")
    response = self.model_manager.generate(
        prompt=full_context,
        system_prompt=system_prompt,
    )
    logger.debug(f"âœ… RÃ©ponse gÃ©nÃ©rÃ©e: {response[:50]}...")

    # === PHASE 6: ANALYSE Ã‰MOTION AVEC CONTEXTE ===
    if self.enable_advanced_ai:
        # Analyse avancÃ©e (avec mÃ©moire Ã©motionnelle)
        emotion, intensity = self.emotion_analyzer.analyze_with_context(
            text=response,
            previous_emotion=self.current_emotion,
            previous_intensity=self.current_intensity,
        )
    else:
        # Analyse basique (keywords uniquement)
        emotion, intensity = self.emotion_analyzer.analyze_emotion(response)

    logger.debug(f"ğŸ¨ Ã‰motion: {emotion} (intensitÃ©: {intensity:.2f})")

    # === PHASE 7: STOCKAGE MÃ‰MOIRE ===
    if self.enable_advanced_ai and self.memory_manager:
        # Stocker message utilisateur
        self.memory_manager.store_message(
            message=user_message,
            role="user",
            metadata={
                "intent": intent,
                "intent_confidence": intent_conf,
                "sentiment": sentiment,
                "sentiment_score": sent_score,
            }
        )

        # Stocker rÃ©ponse assistant
        self.memory_manager.store_message(
            message=response,
            role="assistant",
            metadata={
                "emotion": emotion,
                "intensity": intensity,
            }
        )

    # === PHASE 8: RÃ‰SUMÃ‰ SI NÃ‰CESSAIRE ===
    summary_generated = False

    if self.enable_advanced_ai and self.memory_manager:
        summary = self.memory_manager.summarize_if_needed()
        if summary:
            logger.info(f"ğŸ“ RÃ©sumÃ© conversation gÃ©nÃ©rÃ©: {len(summary)} caractÃ¨res")
            summary_generated = True

    # === PHASE 9: MISE Ã€ JOUR PERSONNALITÃ‰ ===
    if self.enable_advanced_ai and self.personality_engine:
        self.personality_engine.update_traits({
            "user_message": user_message,
            "intent": intent,
            "sentiment": sentiment,
            "response": response,
        })

    # === PHASE 10: MISE Ã€ JOUR Ã‰TAT ACTUEL ===
    self.current_emotion = emotion
    self.current_intensity = intensity

    # Ajouter Ã  historique court-terme (compatibilitÃ©)
    self.conversation_history.append({"role": "user", "content": user_message})
    self.conversation_history.append({"role": "assistant", "content": response})

    # Limiter historique court-terme
    if len(self.conversation_history) > 20:  # AugmentÃ© de 10 Ã  20
        self.conversation_history = self.conversation_history[-20:]

    # === RETOUR RÃ‰SULTAT ===
    return {
        "response": response,
        "emotion": emotion,
        "intensity": intensity,
        # Metadata additionnelles
        "intent": intent,
        "intent_confidence": intent_conf,
        "sentiment": sentiment,
        "sentiment_score": sent_score,
        "summary_generated": summary_generated,
        "advanced_ai_enabled": self.enable_advanced_ai,
    }
```

---

### Ã‰tape 4 : Nouvelle MÃ©thode _build_full_context()

**Ajouter mÃ©thode** :

```python
def _build_full_context(
    self,
    user_message: str,
    relevant_memory: List[str],
    short_term_history: List[dict],
) -> str:
    """
    Construit contexte complet pour LLM.

    Combine :
    - MÃ©moire long-terme pertinente
    - Historique court-terme (10-20 derniers messages)
    - Message utilisateur actuel

    Args:
        user_message: Message actuel utilisateur
        relevant_memory: Contexte pertinent mÃ©moire long-terme
        short_term_history: 10-20 derniers messages

    Returns:
        Contexte formatÃ© pour LLM
    """
    context_parts = []

    # 1. MÃ©moire long-terme (si disponible)
    if relevant_memory:
        context_parts.append("=== Contexte pertinent ===")
        for i, memory in enumerate(relevant_memory, 1):
            context_parts.append(f"{i}. {memory}")
        context_parts.append("")  # Ligne vide

    # 2. Historique court-terme
    if short_term_history:
        context_parts.append("=== Conversation rÃ©cente ===")
        for msg in short_term_history:
            role = "Utilisateur" if msg["role"] == "user" else "Assistant"
            context_parts.append(f"{role}: {msg['content']}")
        context_parts.append("")

    # 3. Message actuel
    context_parts.append("=== Message actuel ===")
    context_parts.append(f"Utilisateur: {user_message}")
    context_parts.append("")
    context_parts.append("Assistant:")

    return "\n".join(context_parts)
```

---

### Ã‰tape 5 : Garder MÃ©thodes Existantes (RÃ©trocompatibilitÃ©)

**MÃ©thodes Ã  GARDER** (utilisÃ©es ailleurs) :

```python
def update_context(self, user_message: str, assistant_response: str):
    """
    Mise Ã  jour contexte (LEGACY - pour compatibilitÃ©).
    UtilisÃ© par certains anciens tests.
    """
    self.conversation_history.append({"role": "user", "content": user_message})
    self.conversation_history.append({"role": "assistant", "content": assistant_response})

    if len(self.conversation_history) > 20:
        self.conversation_history = self.conversation_history[-20:]

def get_conversation_history(self) -> List[dict]:
    """Retourne historique conversation (LEGACY)."""
    return self.conversation_history.copy()

def clear_history(self):
    """Efface historique conversation."""
    self.conversation_history.clear()
    logger.info("ğŸ—‘ï¸ Historique conversation effacÃ©")
```

---

## ğŸ§ª Tests Unitaires Ã  Modifier

**Fichier** : `tests/ai/test_chat_engine.py`

### Ajouter Tests Nouveaux Modules

```python
import pytest
from src.ai.chat_engine import ChatEngine
from src.ai.model_manager import ModelManager

@pytest.fixture
def chat_engine_advanced(model_manager_mock):
    """ChatEngine avec modules IA avancÃ©s activÃ©s."""
    return ChatEngine(model_manager_mock, enable_advanced_ai=True)

@pytest.fixture
def chat_engine_legacy(model_manager_mock):
    """ChatEngine en mode legacy (sans modules avancÃ©s)."""
    return ChatEngine(model_manager_mock, enable_advanced_ai=False)

def test_advanced_modules_initialization(chat_engine_advanced):
    """VÃ©rifie que modules avancÃ©s sont initialisÃ©s."""
    assert chat_engine_advanced.memory_manager is not None
    assert chat_engine_advanced.personality_engine is not None
    assert chat_engine_advanced.context_analyzer is not None

def test_legacy_mode_no_advanced_modules(chat_engine_legacy):
    """VÃ©rifie que mode legacy ne charge pas modules avancÃ©s."""
    assert chat_engine_legacy.memory_manager is None
    assert chat_engine_legacy.personality_engine is None
    assert chat_engine_legacy.context_analyzer is None

def test_generate_response_with_advanced_ai(chat_engine_advanced, model_manager_mock):
    """Test gÃ©nÃ©ration rÃ©ponse avec modules avancÃ©s."""
    model_manager_mock.generate.return_value = "Bonjour ! Comment puis-je t'aider ?"

    result = chat_engine_advanced.generate_response("Bonjour")

    assert "response" in result
    assert "emotion" in result
    assert "intent" in result
    assert "sentiment" in result
    assert result["advanced_ai_enabled"] is True

def test_context_analyzer_detects_intent(chat_engine_advanced):
    """VÃ©rifie dÃ©tection intention par ContextAnalyzer."""
    result = chat_engine_advanced.generate_response("Comment crÃ©er un rappel ?")

    assert result["intent"] == "question"
    assert result["intent_confidence"] > 0.8

def test_memory_stores_messages(chat_engine_advanced, tmp_path):
    """VÃ©rifie stockage messages dans mÃ©moire."""
    chat_engine_advanced.memory_manager.storage_path = str(tmp_path)

    chat_engine_advanced.generate_response("Je m'appelle Alice")

    # VÃ©rifier message stockÃ©
    assert len(chat_engine_advanced.memory_manager.get_recent_messages()) > 0
```

---

## ğŸ”„ Migration Code Existant

### Modules Utilisant ChatEngine

**Fichiers Ã  vÃ©rifier** :

1. `src/gui/app.py` : Interface Qt utilise ChatEngine
2. `src/discord_bot/bot.py` : Bot Discord utilise ChatEngine
3. `tests/ai/test_chat_engine.py` : Tests unitaires

### Changements NÃ©cessaires

#### 1. src/gui/app.py

**Avant** :

```python
self.chat_engine = ChatEngine(self.model_manager)
```

**AprÃ¨s** :

```python
# Activer modules IA avancÃ©s (dÃ©faut: True)
enable_advanced = self.config.get("ai.enable_advanced_features", default=True)
self.chat_engine = ChatEngine(self.model_manager, enable_advanced_ai=enable_advanced)
```

**Ajout dans config.json** :

```json
{
  "ai": {
    "enable_advanced_features": true
  }
}
```

#### 2. Affichage Metadata Interface

**Ajouter dans app.py** (optionnel, pour debug) :

```python
def _display_response_metadata(self, result: dict):
    """Affiche metadata rÃ©ponse IA (debug)."""
    if result.get("advanced_ai_enabled"):
        metadata = []

        if result.get("intent"):
            metadata.append(f"Intent: {result['intent']} ({result['intent_confidence']:.2f})")

        if result.get("sentiment"):
            metadata.append(f"Sentiment: {result['sentiment']} ({result['sentiment_score']:.2f})")

        if result.get("summary_generated"):
            metadata.append("ğŸ“ RÃ©sumÃ© conversation gÃ©nÃ©rÃ©")

        if metadata:
            logger.debug("ğŸ“Š Metadata: " + ", ".join(metadata))
```

---

## âš ï¸ Points d'Attention

### 1. Performances

**Objectif** : Temps rÃ©ponse <3s

**Mesures** :
- âœ… Recherche embeddings : ~50ms (OK)
- âœ… GÃ©nÃ©ration LLM : ~2000ms (OK avec CUDA)
- âœ… Analyse contextuelle : ~10ms (OK)
- âœ… **TOTAL** : ~2100ms âœ…

**Optimisations** :
- Recherche embeddings peut Ãªtre async (parallÃ¨le gÃ©nÃ©ration LLM)
- Cache rÃ©sultats ContextAnalyzer si messages similaires

### 2. Gestion Erreurs

**StratÃ©gies** :

```python
def generate_response(self, user_message: str) -> dict:
    try:
        # ... code gÃ©nÃ©ration ...

    except Exception as e:
        logger.error(f"âŒ Erreur gÃ©nÃ©ration rÃ©ponse: {e}", exc_info=True)

        # Fallback : RÃ©ponse basique sans modules avancÃ©s
        response = "DÃ©solÃ©e, j'ai rencontrÃ© un problÃ¨me. Peux-tu reformuler ?"

        return {
            "response": response,
            "emotion": "neutre",
            "intensity": 0.5,
            "error": str(e),
            "advanced_ai_enabled": self.enable_advanced_ai,
        }
```

### 3. Migrations DonnÃ©es

**Si structures JSON changent** :

```python
# memory_manager.py
def _load_memory(self):
    """Charge mÃ©moire avec migration auto si nÃ©cessaire."""
    try:
        with open(self.conversations_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        # VÃ©rifier version schÃ©ma
        if data.get("version") == "1.0":
            # OK, version actuelle
            return data
        elif data.get("version") == "0.9":
            # Migrer 0.9 â†’ 1.0
            logger.info("ğŸ”„ Migration donnÃ©es 0.9 â†’ 1.0...")
            data = self._migrate_v09_to_v10(data)
            self._save_conversations(data)  # Sauvegarder version migrÃ©e
            return data
        else:
            logger.warning(f"âš ï¸ Version schÃ©ma inconnue: {data.get('version')}")
            return data

    except FileNotFoundError:
        logger.info("ğŸ“ Fichier mÃ©moire non trouvÃ©, crÃ©ation...")
        return self._create_empty_memory()
```

---

## ğŸ“‹ Checklist IntÃ©gration

### Avant Codage

- âœ… Lire ARCHITECTURE.md
- âœ… Lire DATA_SCHEMAS.md
- âœ… Comprendre flux donnÃ©es
- âœ… Identifier modifications ChatEngine nÃ©cessaires

### Pendant Codage

- âœ… CrÃ©er nouveaux modules un par un
- âœ… Tests unitaires chaque module (>80% coverage)
- âœ… Modifier ChatEngine progressivement
- âœ… Garder rÃ©trocompatibilitÃ© (mode legacy)
- âœ… Logs debug abondants

### AprÃ¨s Codage

- âœ… Tests intÃ©gration ChatEngine complet
- âœ… Benchmark temps rÃ©ponse (<3s)
- âœ… VÃ©rifier VRAM (<6 GB)
- âœ… Tests avec UI (app.py)
- âœ… Tests avec Discord bot
- âœ… Documentation mise Ã  jour

---

## ğŸ¯ Ordre ImplÃ©mentation RecommandÃ©

### Phase 1 : MÃ©moire Long-Terme (PrioritÃ© HAUTE)

1. CrÃ©er `MemoryManager` (squelette)
2. CrÃ©er `ConversationSummarizer`
3. CrÃ©er `FactExtractor`
4. ComplÃ©ter `MemoryManager`
5. Tests unitaires (3 modules)
6. **IntÃ©grer dans ChatEngine** (phases 2, 7, 8)

### Phase 2 : PersonnalitÃ© Ã‰volutive

1. CrÃ©er `PersonalityEngine`
2. Tests unitaires
3. **IntÃ©grer dans ChatEngine** (phases 3, 9)

### Phase 3 : Ã‰motions AvancÃ©es

1. AmÃ©liorer `EmotionAnalyzer`
2. CrÃ©er `EmotionMemory`
3. Tests unitaires
4. **IntÃ©grer dans ChatEngine** (phase 6)

### Phase 4 : Analyse Contextuelle

1. CrÃ©er `ContextAnalyzer`
2. Tests unitaires
3. **IntÃ©grer dans ChatEngine** (phase 1)

### Phase 5 : Tests IntÃ©gration Finaux

1. Tests ChatEngine complet
2. Tests app.py + Discord
3. Benchmarks performance
4. Corrections bugs
5. Documentation finale

---

**CrÃ©Ã© le** : 16 novembre 2025
**DerniÃ¨re mise Ã  jour** : 16 novembre 2025
