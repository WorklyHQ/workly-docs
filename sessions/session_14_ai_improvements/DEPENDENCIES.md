# üì¶ D√©pendances Python - Session 14

**Date** : 16 novembre 2025
**Version** : 0.18.0-alpha (cible)

---

## üìä √âtat Actuel

### Packages D√©j√† Install√©s

**V√©rification effectu√©e** : 16 novembre 2025

| Package | Version | Statut | Utilisation |
|---------|---------|--------|-------------|
| `Python` | 3.10.9 | ‚úÖ OK | Runtime principal |
| `PySide6` | (install√©) | ‚úÖ OK | Interface Qt GUI |
| `numpy` | (install√©) | ‚úÖ OK | Calculs cosine similarity |
| `llama-cpp-python` | (avec CUDA) | ‚úÖ OK | Mod√®le LLM Zephyr-7B |
| `discord.py` | (install√©) | ‚úÖ OK | Bot Discord |
| `pytest` | (install√©) | ‚úÖ OK | Tests unitaires |

**Commande v√©rification** :

```powershell
cd c:\Dev\workly_project\workly-desktop
.\venv\Scripts\Activate.ps1
python -c "import sys; print('Python:', sys.version.split()[0]); import PySide6; print('‚úÖ PySide6'); import numpy; print('‚úÖ numpy')"
```

---

## üì• Packages √† Installer (Phase 1)

### sentence-transformers

**Description** : Mod√®les embeddings pr√©-entra√Æn√©s pour recherche s√©mantique

**Utilisation** : MemoryManager - Recherche contexte pertinent dans m√©moire long-terme

**Taille** :
- Package : ~50 MB
- Mod√®le `all-MiniLM-L6-v2` : ~80 MB
- D√©pendances (torch, transformers, etc.) : ~200 MB
- **Total estim√©** : ~330 MB

**Installation** :

```powershell
cd c:\Dev\workly_project\workly-desktop
.\venv\Scripts\Activate.ps1

pip install sentence-transformers

# V√©rification
python -c "from sentence_transformers import SentenceTransformer; print('‚úÖ sentence-transformers OK')"
```

**Premier run** (t√©l√©charge mod√®le automatiquement) :

```python
from sentence_transformers import SentenceTransformer

# T√©l√©charge all-MiniLM-L6-v2 (~80 MB) au premier appel
model = SentenceTransformer('all-MiniLM-L6-v2')
```

**Cache mod√®le** : `C:\Users\<username>\.cache\torch\sentence_transformers\`

---

## üìã D√©pendances Compl√®tes (requirements.txt)

### Fichier Actuel

**Emplacement** : `workly-desktop/requirements.txt`

**Contenu actuel estim√©** :

```
PySide6>=6.5.0
llama-cpp-python
discord.py>=2.3.0
python-dotenv
pytest>=7.4.0
```

### Ajouts Session 14

**Ajouter dans requirements.txt** :

```
# === Session 14: Am√©liorations IA ===
sentence-transformers>=2.2.0  # Embeddings pour recherche s√©mantique
```

### requirements.txt Complet Sugg√©r√©

```txt
# === Core GUI ===
PySide6>=6.5.0

# === IA & LLM ===
llama-cpp-python  # Mod√®le Zephyr-7B local (CUDA support)
sentence-transformers>=2.2.0  # Embeddings recherche s√©mantique

# === Discord Bot ===
discord.py>=2.3.0

# === Utilities ===
python-dotenv  # Variables environnement (.env)
numpy>=1.24.0  # Calculs num√©riques

# === Tests ===
pytest>=7.4.0
pytest-cov>=4.1.0  # Coverage reports
pytest-asyncio>=0.21.0  # Tests async Discord

# === Development (optionnel) ===
# black  # Code formatting
# flake8  # Linting
# mypy  # Type checking
```

---

## üîß Installation Compl√®te Nouveau Environnement

### Depuis Z√©ro

```powershell
# 1. Cr√©er venv
python -m venv venv

# 2. Activer venv
.\venv\Scripts\Activate.ps1

# 3. Mettre √† jour pip
python -m pip install --upgrade pip

# 4. Installer llama-cpp-python avec CUDA
$env:CMAKE_ARGS="-DLLAMA_CUDA=on"
$env:FORCE_CMAKE="1"
pip install llama-cpp-python --force-reinstall --no-cache-dir --verbose

# 5. Installer autres packages
pip install -r requirements.txt

# 6. V√©rifier installation
pytest tests/ -v
```

**Dur√©e totale** : ~30-40 minutes (compilation CUDA longue)

---

## üìä Comparaison Tailles

### Avant Session 14

| Composant | Taille |
|-----------|--------|
| venv/ (packages Python) | ~3 GB |
| models/ (Zephyr-7B) | 6.8 GB |
| data/ (config, logs) | <10 MB |
| **TOTAL** | ~9.8 GB |

### Apr√®s Session 14

| Composant | Taille |
|-----------|--------|
| venv/ (packages Python) | ~3.3 GB (+300 MB sentence-transformers) |
| models/ (Zephyr-7B) | 6.8 GB |
| data/ (config, logs, **memory**, **personality**, **emotions**) | ~50 MB (+40 MB donn√©es IA) |
| **TOTAL** | ~10.15 GB (+350 MB) |

**Impact** : +350 MB (~3.5% augmentation)

---

## üö® Pr√©requis Syst√®me

### Hardware Minimum

- **CPU** : Intel i5 ou √©quivalent (4+ cores)
- **RAM** : 16 GB (8 GB syst√®me + 8 GB app)
- **GPU** : NVIDIA GTX 1060 ou sup√©rieur (6 GB VRAM minimum)
- **Disque** : 15 GB espace libre (SSD recommand√©)

### Software Pr√©requis

- **Windows** : 10 ou 11 (64-bit)
- **Python** : 3.10+ (3.10.9 recommand√©)
- **CUDA Toolkit** : 11.x ou 12.x (inclus dans drivers NVIDIA)
- **Drivers NVIDIA** : R√©cents (Game Ready ou Studio)
- **Visual Studio Build Tools** : Pour compilation llama-cpp-python

---

## üîç V√©rification Installation Compl√®te

### Script Test

**Fichier** : `scripts/verify_dependencies.py`

```python
#!/usr/bin/env python3
"""V√©rifie toutes d√©pendances Session 14."""

import sys
from importlib import import_module

def check_package(name: str, display_name: str = None) -> bool:
    """V√©rifie si package importable."""
    display = display_name or name
    try:
        import_module(name)
        print(f"‚úÖ {display}")
        return True
    except ImportError:
        print(f"‚ùå {display} NOT INSTALLED")
        return False

def main():
    print("=== V√©rification D√©pendances Workly Session 14 ===\n")

    print(f"Python version: {sys.version.split()[0]}")

    if sys.version_info < (3, 10):
        print("‚ö†Ô∏è  WARNING: Python 3.10+ recommand√©")

    print("\n--- Packages Core ---")
    results = []
    results.append(check_package("PySide6", "PySide6 (Qt GUI)"))
    results.append(check_package("numpy", "numpy (calculs)"))

    print("\n--- Packages IA ---")
    results.append(check_package("llama_cpp", "llama-cpp-python (LLM)"))
    results.append(check_package("sentence_transformers", "sentence-transformers (embeddings)"))

    print("\n--- Packages Discord ---")
    results.append(check_package("discord", "discord.py (bot)"))

    print("\n--- Packages Tests ---")
    results.append(check_package("pytest", "pytest (tests unitaires)"))

    # V√©rifier CUDA
    print("\n--- CUDA Support ---")
    try:
        from llama_cpp import Llama
        cuda_available = hasattr(Llama, '__init__')  # Simplifi√©
        print(f"‚úÖ CUDA support detected" if cuda_available else "‚ö†Ô∏è  CUDA support unknown")
    except:
        print("‚ùå llama-cpp-python not working")

    # R√©sum√©
    print("\n" + "=" * 50)
    success = sum(results)
    total = len(results)
    print(f"R√©sultat: {success}/{total} packages OK")

    if success == total:
        print("‚úÖ Toutes d√©pendances install√©es !")
        return 0
    else:
        print("‚ùå Certaines d√©pendances manquantes")
        print("\nInstaller avec : pip install -r requirements.txt")
        return 1

if __name__ == "__main__":
    sys.exit(main())
```

**Ex√©cution** :

```powershell
.\venv\Scripts\Activate.ps1
python scripts/verify_dependencies.py
```

---

## üêõ Troubleshooting

### Probl√®me 1 : sentence-transformers Lent au Premier Run

**Sympt√¥me** : Premier `SentenceTransformer('all-MiniLM-L6-v2')` prend 1-2 minutes

**Cause** : T√©l√©chargement mod√®le depuis HuggingFace (~80 MB)

**Solution** : Normal, attendre t√©l√©chargement. Ensuite en cache.

### Probl√®me 2 : Erreur Import sentence_transformers

**Sympt√¥me** :
```
ModuleNotFoundError: No module named 'sentence_transformers'
```

**Solution** :
```powershell
.\venv\Scripts\Activate.ps1
pip install sentence-transformers
```

### Probl√®me 3 : CUDA Not Available

**Sympt√¥me** :
```python
# Test CUDA
from llama_cpp import Llama
print(hasattr(Llama, 'n_gpu_layers'))  # False
```

**Solution** : R√©installer llama-cpp-python avec CUDA :

```powershell
$env:CMAKE_ARGS="-DLLAMA_CUDA=on"
$env:FORCE_CMAKE="1"
pip install llama-cpp-python --force-reinstall --no-cache-dir --verbose
```

Voir `docs/chat_transitions/chat_12_gpu_ui_discord/TROUBLESHOOTING.md` pour d√©tails.

---

## üìö Documentation Packages

### sentence-transformers

**Docs officielles** : https://www.sbert.net/

**Mod√®les disponibles** : https://www.sbert.net/docs/pretrained_models.html

**Mod√®le utilis√©** : `all-MiniLM-L6-v2`
- Dimension : 384
- Taille : 80 MB
- Performance : Bon √©quilibre vitesse/qualit√©
- Langue : Multilingue (inclut fran√ßais)

**Exemple utilisation** :

```python
from sentence_transformers import SentenceTransformer
import numpy as np

# Charger mod√®le (t√©l√©charge au 1er run)
model = SentenceTransformer('all-MiniLM-L6-v2')

# Encoder textes
texts = ["Bonjour", "Hello", "Salut"]
embeddings = model.encode(texts)

# embeddings.shape = (3, 384)

# Cosine similarity
from numpy import dot
from numpy.linalg import norm

def cosine_similarity(a, b):
    return dot(a, b) / (norm(a) * norm(b))

sim = cosine_similarity(embeddings[0], embeddings[2])
print(f"Similarit√© 'Bonjour' vs 'Salut': {sim:.3f}")  # ~0.85
```

---

## ‚úÖ Checklist Installation Phase 1

Avant de commencer codage Phase 1 :

- ‚úÖ venv activ√© (`.\venv\Scripts\Activate.ps1`)
- ‚úÖ `sentence-transformers` install√©
- ‚úÖ Import `from sentence_transformers import SentenceTransformer` OK
- ‚úÖ Mod√®le `all-MiniLM-L6-v2` t√©l√©charg√© (auto au 1er run)
- ‚úÖ `numpy` disponible
- ‚úÖ Script `verify_dependencies.py` passe

**Commande rapide** :

```powershell
.\venv\Scripts\Activate.ps1
pip install sentence-transformers
python -c "from sentence_transformers import SentenceTransformer; m = SentenceTransformer('all-MiniLM-L6-v2'); print('‚úÖ OK')"
```

---

**Cr√©√© le** : 16 novembre 2025
**Derni√®re mise √† jour** : 16 novembre 2025
