# üîß Troubleshooting - Chat 12

Guide de r√©solution des probl√®mes rencontr√©s pendant le Chat 12.

---

## üêõ Probl√®me 1 : Performances IA Extr√™mement Lentes (51s par r√©ponse)

### Sympt√¥mes
- R√©ponses IA prennent 40-60 secondes au lieu de ~2 secondes
- Logs montrent : "Profil GPU auto-d√©tect√© : 'performance' (RTX 4050, 6.0 GB VRAM)"
- Configuration correcte : `gpu_layers=-1`, profil `performance`
- Utilisateur note : "Le mod√®le est lanc√© sur la ram et pas la vram"

### Diagnostic

**Test 1 : V√©rifier CUDA disponibilit√©**
```powershell
cd c:\Dev\workly_project\workly-desktop
.\venv\Scripts\Activate.ps1
python -c "from llama_cpp import Llama; print('CUDA available:', hasattr(Llama, 'n_gpu_layers'))"
```

**R√©sultat attendu** : `CUDA available: True`
**Si False** ‚Üí llama-cpp-python install√© sans support CUDA

### Cause Racine
`llama-cpp-python` install√© en version CPU-only (sans CUDA), probablement parce que :
1. Installation initiale sans variable d'environnement `CMAKE_ARGS="-DLLAMA_CUDA=on"`
2. Cache pip gardait l'ancienne version
3. Wheels pr√©compil√©s CPU-only install√©s par d√©faut

### Solution

**√âtape 1 : Activer environnement virtuel**
```powershell
cd c:\Dev\workly_project\workly-desktop
.\venv\Scripts\Activate.ps1
```

**√âtape 2 : R√©installer avec support CUDA**
```powershell
$env:CMAKE_ARGS="-DLLAMA_CUDA=on"
$env:FORCE_CMAKE="1"
pip install llama-cpp-python --force-reinstall --no-cache-dir --verbose
```

**‚ö†Ô∏è Dur√©e** : ~15-20 minutes (compilation compl√®te)

**√âtape 3 : V√©rifier installation**
```powershell
python -c "from llama_cpp import Llama; print('CUDA available:', hasattr(Llama, 'n_gpu_layers'))"
```

**R√©sultat attendu** : `CUDA available: True`

**√âtape 4 : Relancer l'application**
```powershell
.\venv\Scripts\python.exe main.py
```

**V√©rification** : Temps de r√©ponse doit passer de ~51s √† ~2s

### Pr√©requis

**Pour que CUDA fonctionne** :
1. ‚úÖ GPU NVIDIA compatible (GTX 10xx ou plus r√©cent)
2. ‚úÖ Drivers NVIDIA √† jour (Game Ready ou Studio)
3. ‚úÖ CUDA Toolkit 11.x ou 12.x (souvent inclus dans drivers)
4. ‚úÖ Visual Studio Build Tools (pour compilation)

**V√©rifier drivers NVIDIA** :
```powershell
nvidia-smi
```

### Pr√©vention Future

**Pour distribution publique** :
- Wheels pr√©compil√©s officiels incluent d√©j√† CUDA support
- Utilisateurs n'auront besoin que de drivers NVIDIA √† jour
- Syst√®me de profils GPU auto-d√©tecte et configure automatiquement

**Pour d√©veloppement local** :
- Toujours installer avec `CMAKE_ARGS="-DLLAMA_CUDA=on"`
- Documenter pr√©requis dans README.md
- Ajouter section "Installation GPU" dans documentation

---

## üêõ Probl√®me 2 : Auto-Reply Discord Ne Fonctionne Pas

### Sympt√¥mes
- Logs montrent : `KiraDiscordBot initialis√© (auto_reply=False, channels=1)`
- Salons configur√©s dans interface mais bot ne r√©pond pas
- `config.json` contient bien `auto_reply_enabled: true`

### Diagnostic

**V√©rifier config.json** :
```json
"discord": {
    "auto_reply_enabled": true,
    "auto_reply_channels": [123456789012345678],
    "rate_limit_seconds": 3
}
```

**V√©rifier logs bot** :
```
INFO:src.discord_bot.bot:‚úÖ KiraDiscordBot initialis√© (auto_reply=False, channels=1)
```

‚Üí **Incoh√©rence** : Config dit `true`, bot lit `False`

### Cause Racine

**3 probl√®mes identifi√©s** :

1. **Pas de contr√¥le UI** : Interface n'avait pas de checkbox pour activer/d√©sactiver auto-reply
2. **Config non recharg√©e** : Bot d√©marre avec config initiale, jamais recharg√©e apr√®s modifications
3. **Sauvegarde incompl√®te** : Interface ne sauvegardait pas `auto_reply_enabled`, seulement les IDs salons

### Solution

**Modifications apport√©es dans `src/gui/app.py`** :

**1. Ajout checkbox dans dialog** :
```python
# manage_auto_reply_channels()
enable_checkbox = QCheckBox("‚úÖ Activer l'auto-reply dans les salons configur√©s")
enable_checkbox.setChecked(auto_reply_enabled)
```

**2. Modification _save_channels()** :
```python
def _save_channels(self, list_widget, enable_checkbox, dialog):
    # R√©cup√©rer √©tat checkbox
    auto_reply_enabled = enable_checkbox.isChecked()

    # Sauvegarder dans config
    self.config.set("discord.auto_reply_enabled", auto_reply_enabled)
    self.config.set("discord.auto_reply_channels", auto_reply_channels)

    # Recharger config du bot EN TEMPS R√âEL (CRUCIAL!)
    if self.discord_manager and self.discord_manager.bot:
        self.discord_manager.bot.auto_reply_enabled = auto_reply_enabled
        self.discord_manager.bot.auto_reply_channels = auto_reply_channels
```

### Utilisation

**Apr√®s fix** :

1. Ouvrir Discord ‚Üí G√©rer Salons Auto-Reply
2. ‚úÖ **Cocher** "Activer l'auto-reply dans les salons configur√©s"
3. Ajouter IDs des salons (Copier ID depuis Discord)
4. Cliquer "OK"
5. **Pas besoin de red√©marrer l'app !** Config recharg√©e automatiquement

**V√©rification** :
```
‚úÖ Config Discord sauvegard√©e : auto_reply=True, 1 salons
‚úÖ Config bot Discord recharg√©e : auto_reply=True, 1 salons
```

### Obtenir l'ID d'un salon Discord

1. Discord ‚Üí Param√®tres ‚Üí Avanc√©s ‚Üí **Activer Mode D√©veloppeur**
2. Clic droit sur le salon ‚Üí **Copier l'identifiant**
3. Coller l'ID dans l'interface Workly

**Format ID** : Nombre √† 18 chiffres (ex: `1234567890123456789`)

### Tester Auto-Reply

**Configuration minimale** :
1. ‚úÖ Bot Discord d√©marr√© (onglet Discord)
2. ‚úÖ Auto-reply activ√©e (checkbox coch√©e)
3. ‚úÖ Au moins 1 salon configur√© avec ID valide
4. ‚úÖ Bot a acc√®s au salon sur Discord

**Test** :
1. Envoyer un message dans le salon configur√©
2. Bot doit r√©pondre automatiquement
3. Rate limit : 3 secondes entre r√©ponses par utilisateur

**Si ne fonctionne pas** :
- V√©rifier logs onglet üìã Logs
- V√©rifier permissions bot Discord (lecture/√©criture messages)
- V√©rifier ID salon correct (18 chiffres)

---

## üìã Checklist de Diagnostic G√©n√©ral

### Avant de D√©bugger

**V√©rifier logs** :
1. Ouvrir onglet üìã Logs dans l'application
2. Chercher messages ERROR (rouge) ou WARNING (orange)
3. Noter le module et le message d'erreur

**V√©rifier configuration** :
1. Fichier `data/config.json` existe
2. Permissions lecture/√©criture OK
3. Format JSON valide (pas d'erreur syntax)

**V√©rifier environnement** :
```powershell
# Activer venv
.\venv\Scripts\Activate.ps1

# V√©rifier Python
python --version  # Doit √™tre 3.10+

# V√©rifier packages critiques
pip show llama-cpp-python
pip show PySide6
pip show discord.py
```

### Probl√®mes Courants

**IA ne charge pas** :
- ‚úÖ Fichier mod√®le existe dans `models/` ?
- ‚úÖ GPU d√©tect√© ? (V√©rifier label profil GPU)
- ‚úÖ VRAM suffisante ? (6GB recommand√© pour Zephyr-7B)
- ‚úÖ Profil GPU adapt√© ? (Essayer "Auto")

**Discord bot ne d√©marre pas** :
- ‚úÖ Token Discord valide dans `.env` ?
- ‚úÖ Permissions bot Discord correctes ?
- ‚úÖ Bot invit√© sur le serveur Discord ?
- ‚úÖ Intents activ√©s (Message Content Intent) ?

**Performance lente** :
- ‚úÖ CUDA disponible ? (Test ci-dessus)
- ‚úÖ Profil GPU = Performance ou Auto ?
- ‚úÖ GPU layers = -1 (toutes les layers sur GPU) ?
- ‚úÖ Pas de processus gourmand en background ?

---

## üîó Ressources

**Documentation** :
- [CURRENT_STATE.md](CURRENT_STATE.md) : √âtat actuel du projet
- [CHANGELOG.md](../../CHANGELOG.md) : Historique versions
- [llama-cpp-python CUDA](https://github.com/abetlen/llama-cpp-python#installation-with-hardware-acceleration) : Installation GPU officielle

**Support** :
- Discord Workly : https://discord.gg/3Cpyxg29B4
- Issues GitHub : https://github.com/WorklyHQ/workly-desktop/issues
