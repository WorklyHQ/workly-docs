# üéØ CONTEXT_FOR_NEXT_CHAT - Instructions pour Chat 11

**Date :** Novembre 2025  
**De :** Chat 10  
**Pour :** Chat 11  
**Focus :** Session 11 Phases 4-6 (CPU, GPU, Tests)

---

## üöÄ Ce Que Tu Dois Savoir

### üìã √âtat Actuel du Projet

**Desktop-Mate** est une application hybride **Unity + Python** avec avatar VRM interactif.

**Sessions compl√©t√©es :** 11 sessions (Session 11 √† 50%)
- Sessions 0-10 : Setup, VRM, Expressions, Animations, LLM, Discord Bot ‚úÖ
- **Session 11** : Performance Optimizations (3/6 phases compl√©t√©es)

**Ton travail dans Chat 11 :**
- ‚úÖ Phase 1 : Memory Profiling (TERMIN√âE)
- ‚úÖ Phase 2 : LLM Cache Optimization (TERMIN√âE)
- ‚úÖ Phase 3 : IPC Batching (TERMIN√âE)
- üéØ **Phase 4 : CPU Optimization** ‚Üê **COMMENCE ICI**
- üéØ **Phase 5 : GPU Profiling & Tuning**
- üéØ **Phase 6 : Tests & Documentation Finale**

---

## üéì Niveau de l'Utilisateur

‚ö†Ô∏è **IMPORTANT : L'utilisateur ne conna√Æt PAS Unity ni C#**

Tu dois **TOUJOURS** :
1. ‚úÖ Expliquer clairement les concepts techniques
2. ‚úÖ Donner des instructions pas-√†-pas (o√π cr√©er les fichiers, comment les configurer)
3. ‚úÖ D√©crire ce qu'il doit voir dans Unity (interface, console, r√©sultats)
4. ‚úÖ √ätre p√©dagogue et patient
5. ‚úÖ Demander confirmation avant les changements majeurs

**Langue :** üá´üá∑ **TOUJOURS en fran√ßais**

---

## üö® R√àGLES ABSOLUES DE DOCUMENTATION

### ‚ö†Ô∏è SYST√àME ANTI-OUBLI (CRITIQUE !)

**AVANT de dire "Termin√©", tu DOIS v√©rifier cette checklist :**

```
‚ñ° Ai-je cr√©√© des fichiers ? ‚Üí MAJ docs/INDEX.md
‚ñ° Ai-je modifi√© l'architecture ? ‚Üí MAJ README.md racine + docs/README.md
‚ñ° Ai-je cr√©√© des scripts ? ‚Üí COPIER dans docs/session_11_performance/scripts/
‚ñ° Ai-je termin√© une phase ? ‚Üí MAJ README.md racine (4 sections !)
‚ñ° Tests passent ? ‚Üí pytest OK
‚ñ° Erreurs v√©rifi√©es ? ‚Üí Python + Unity OK
‚ñ° R√©capitulatif affich√© ? ‚Üí Template de r√©ponse complet
```

**üö® SI UNE SEULE case manque ‚Üí NE DIS PAS "Termin√©" !**

### üìö Fichiers √† TOUJOURS Mettre √† Jour

Apr√®s **CHAQUE** modification (code, bug fix, nouvelle feature...), tu dois **SYST√âMATIQUEMENT** mettre √† jour :

| Fichier | Emplacement | Quand |
|---------|-------------|-------|
| `INDEX.md` | `docs/` | Nouveaux fichiers cr√©√©s |
| `README.md` (docs) | `docs/` | Architecture modifi√©e, nouvelle session |
| `README.md` (racine) | Racine projet | **4 SECTIONS** √† chaque fin de phase ! |
| `session_11_performance/[fichier].md` | `docs/sessions/` | Phase en cours |

### üö® README.md RACINE : 4 SECTIONS OBLIGATOIRES

**√Ä la fin de CHAQUE PHASE, tu DOIS mettre √† jour :**

1. **Section "Sessions document√©es"** (ligne ~393)
   ```markdown
   N. **[Session N - Phase X](docs/sessions/session_N/)** ‚úÖ
      - Fonctionnalit√©s impl√©ment√©es
      - Technologies utilis√©es
      - Message de succ√®s ! üé≠‚ú®
   ```

2. **Section "Guides sp√©cifiques"** (ligne ~475)
   ```markdown
   - [Guide Phase X](docs/sessions/session_N/GUIDE_PHASE_X.md) ‚ú® **Description !**
   ```

3. **Section "Changelog"** (ligne ~548)
   ```markdown
   ### Version 0.X.0-alpha (DATE) ‚ú® **NOUVEAU - SESSION N PHASE X**
   - ‚úÖ Liste COMPL√àTE des fonctionnalit√©s
   - ‚úÖ Scripts cr√©√©s
   - ‚úÖ Bugs r√©solus
   - üé≠ **Message de succ√®s enthousiaste !** ‚ú®
   ```

4. **Section "Status final"** (derni√®re ligne avant √©toile)
   ```markdown
   **üéä Status actuel : [Phase X] COMPL√àTE ! [Capacit√©s actuelles] ! ‚ú®**
   **üöÄ Prochaine √©tape (Chat N - Phase Y) : [Prochaine phase] ! ü§ñ**
   ```

**‚ö†Ô∏è SI TU OUBLIES ‚Üí L'utilisateur va te le rappeler ‚Üí TU AS √âCHOU√â !**

### üìÇ R√àGLE SP√âCIALE : Dossier `scripts/`

**OBLIGATION :**
Chaque fois que tu cr√©es ou modifies un script (`.py`, `.cs`, etc.), tu DOIS :

1. ‚úÖ **CR√âER** `docs/session_11_performance/scripts/` si absent
2. ‚úÖ **COPIER** les versions finales des scripts dans ce dossier
3. ‚úÖ **V√âRIFIER** que TOUS les fichiers sont bien copi√©s

**‚ö†Ô∏è NE JAMAIS oublier ce dossier !**

---

## üìä Performance Actuelle (Baseline apr√®s Phases 1-3)

### LLM Performance
```
‚úÖ Load model : ~2.57s (avec warming cache)
‚úÖ First generation : 1.75s (22.28 tok/s)
‚úÖ Am√©lioration Phase 2 : -16.9% latency, +14.4% speed
```

### IPC Performance
```
‚úÖ Baseline : 0.371 ms (commandes uniques)
‚úÖ Batching : 0.060 ms (par commande en batch)
‚úÖ Am√©lioration Phase 3 : -79.3% latency, +907% throughput
```

### Memory Usage
```
‚úÖ Baseline : 35 MB RAM, 668 MB VRAM
‚úÖ LLM charg√© : 411 MB RAM, 6012 MB VRAM
‚úÖ Apr√®s 100 msgs : 299 MB RAM, 6089 MB VRAM
‚úÖ Fuites m√©moire : AUCUNE (Phase 1)
```

### GPU Usage (‚ö†Ô∏è Point d'attention !)
```
‚ö†Ô∏è VRAM utilis√©e : 6012 MB / 6144 MB (98%)
‚ö†Ô∏è Marge : Seulement 132 MB (2%)
üéØ Phase 5 : Monitoring temps r√©el + alertes
```

---

## üéØ Phase 4 : CPU Optimization (√Ä FAIRE EN PRIORIT√â)

### Objectif
D√©tecter et configurer automatiquement le nombre optimal de threads CPU pour le LLM.

**Probl√®me actuel :** `n_threads=6` hardcod√© dans `src/ai/config.py`

**Solution :** D√©tection automatique bas√©e sur le CPU disponible.

### Plan d'Impl√©mentation

#### 1. Cr√©er `src/utils/cpu_detection.py`

**Emplacement :** `c:\Dev\desktop-mate\src\utils\cpu_detection.py`

**Fonctions √† impl√©menter :**
```python
import psutil
import platform

def get_cpu_info() -> dict:
    """Retourne infos CPU (cores, threads, fr√©quence, architecture)."""
    return {
        "physical_cores": psutil.cpu_count(logical=False),
        "logical_cores": psutil.cpu_count(logical=True),
        "cpu_freq": psutil.cpu_freq().current,
        "architecture": platform.machine()
    }

def calculate_optimal_threads() -> int:
    """Calcule threads optimaux.
    
    Logique :
    - D√©tecte cores physiques
    - R√©serve 2 threads pour l'OS
    - Limite √† 12 threads max (diminishing returns)
    - Retourne min(cores - 2, 12)
    """
    physical_cores = psutil.cpu_count(logical=False)
    optimal = max(1, physical_cores - 2)
    return min(optimal, 12)

def validate_thread_count(n_threads: int) -> bool:
    """Valide si n_threads est valide pour le CPU actuel."""
    max_threads = psutil.cpu_count(logical=True)
    return 1 <= n_threads <= max_threads
```

#### 2. Cr√©er `scripts/benchmark_cpu_threads.py`

**Emplacement :** `c:\Dev\desktop-mate\scripts\benchmark_cpu_threads.py`

**Objectif :** Tester diff√©rentes configurations de threads (1, 2, 4, 6, 8, 12)

**M√©triques √† mesurer :**
```python
# Pour chaque configuration de threads :
- Latence moyenne (ms)
- Throughput (tokens/s)
- CPU usage (%)
- Temps de g√©n√©ration de 100 tokens
```

**Structure du script :**
```python
import time
import psutil
from src.ai.model_manager import ModelManager
from src.ai.config import LlamaModelConfig

def benchmark_thread_config(n_threads: int):
    """Benchmark une configuration de threads."""
    # 1. Cr√©er config avec n_threads sp√©cifique
    # 2. Charger le mod√®le
    # 3. G√©n√©rer 10 messages de test
    # 4. Mesurer latence, throughput, CPU usage
    # 5. Retourner r√©sultats

def run_benchmarks():
    """Teste toutes les configurations."""
    configs = [1, 2, 4, 6, 8, 12]
    results = []
    
    for n_threads in configs:
        print(f"Testing {n_threads} threads...")
        results.append(benchmark_thread_config(n_threads))
    
    # Afficher tableau comparatif
    display_results(results)
    
    # Identifier configuration optimale
    optimal = find_optimal(results)
    print(f"\nOptimal configuration: {optimal} threads")
```

#### 3. Modifier `src/ai/config.py`

**Fichier :** `c:\Dev\desktop-mate\src\ai\config.py`

**Changement :**
```python
# AVANT (hardcod√©)
n_threads = 6

# APR√àS (automatique)
from src.utils.cpu_detection import calculate_optimal_threads
n_threads = calculate_optimal_threads()
```

**‚ö†Ô∏è Tester avant de commiter !**

### Tests √† Effectuer

```powershell
# Activer venv
venv\Scripts\Activate.ps1

# 1. Tester le module de d√©tection
python -c "from src.utils.cpu_detection import get_cpu_info, calculate_optimal_threads; print(get_cpu_info()); print(f'Optimal: {calculate_optimal_threads()} threads')"

# 2. Lancer le benchmark complet
python scripts/benchmark_cpu_threads.py

# 3. V√©rifier que le LLM charge correctement avec auto-d√©tection
python -c "from src.ai.config import LlamaModelConfig; print(LlamaModelConfig().n_threads)"

# 4. Tests unitaires
pytest tests/
```

### R√©sultats Attendus

**Gain de performance attendu : +5-15%** (selon CPU)

**Exemple de r√©sultats :**
```
Threads | Latency (ms) | Throughput (tok/s) | CPU Usage (%)
--------|--------------|--------------------|--------------
1       | 4200         | 8.5                | 25%
2       | 2800         | 13.2               | 40%
4       | 1900         | 18.7               | 65%
6       | 1750         | 22.3               | 80%  ‚Üê Baseline actuel
8       | 1680         | 23.1               | 90%  ‚Üê Optimal possible
12      | 1690         | 22.8               | 95%  (diminishing returns)

Optimal : 8 threads (gain +3.6% vs baseline)
```

### Documentation √† Cr√©er

**Fichier :** `docs/sessions/session_11_performance/CPU_OPTIMIZATION.md`

**Contenu :**
1. Objectif et probl√®me identifi√©
2. Solution : D√©tection automatique
3. Impl√©mentation (code Python)
4. Benchmark (r√©sultats avec graphique)
5. R√©sultats (gain de performance)
6. Recommandations d'usage

**‚ö†Ô∏è NE PAS OUBLIER :**
- ‚úÖ Copier les scripts dans `docs/session_11_performance/scripts/`
- ‚úÖ Mettre √† jour `docs/INDEX.md`
- ‚úÖ Mettre √† jour `docs/README.md`
- ‚úÖ Mettre √† jour `README.md` racine (4 sections !)

---

## üîú Phase 5 : GPU Profiling & Tuning (Apr√®s Phase 4)

### Objectif
Monitorer la charge GPU en temps r√©el et √©viter les crashs par saturation VRAM.

**Probl√®me actuel :**
- ‚ö†Ô∏è VRAM √† 98% (6012 MB / 6144 MB)
- ‚ö†Ô∏è Seulement 132 MB de marge
- ‚ö†Ô∏è Risque de crash si pic VRAM (ex: multiples mod√®les charg√©s)

### Plan d'Impl√©mentation

#### 1. Cr√©er `src/utils/gpu_monitor.py`

**Fonctions √† impl√©menter :**
```python
import pynvml

def init_nvml():
    """Initialise NVML."""
    pynvml.nvmlInit()

def get_gpu_info() -> dict:
    """Retourne infos GPU (nom, VRAM, temp√©rature, utilisation)."""
    handle = pynvml.nvmlDeviceGetHandleByIndex(0)
    return {
        "name": pynvml.nvmlDeviceGetName(handle),
        "total_memory": pynvml.nvmlDeviceGetMemoryInfo(handle).total,
        "used_memory": pynvml.nvmlDeviceGetMemoryInfo(handle).used,
        "free_memory": pynvml.nvmlDeviceGetMemoryInfo(handle).free,
        "temperature": pynvml.nvmlDeviceGetTemperature(handle, 0),
        "utilization": pynvml.nvmlDeviceGetUtilizationRates(handle).gpu
    }

def is_vram_critical() -> bool:
    """Retourne True si VRAM > 90%."""
    info = get_gpu_info()
    usage_percent = (info["used_memory"] / info["total_memory"]) * 100
    return usage_percent > 90

def suggest_profile() -> str:
    """Sugg√®re un profil adapt√© selon VRAM disponible."""
    info = get_gpu_info()
    total_gb = info["total_memory"] / (1024**3)
    
    if total_gb < 4:
        return "low_memory"
    elif total_gb < 6:
        return "balanced"
    else:
        return "performance"
```

#### 2. Cr√©er `scripts/benchmark_gpu_profiles.py`

**Objectif :** Tester 3 profils GPU et identifier le plus stable.

**Profils √† tester :**
```python
GPU_PROFILES = {
    "low_memory": {
        "n_gpu_layers": 20,
        "n_batch": 256,
        "target_vram": "2-4 GB"
    },
    "balanced": {
        "n_gpu_layers": 32,
        "n_batch": 512,
        "target_vram": "4-6 GB"
    },
    "performance": {
        "n_gpu_layers": 43,  # Actuel
        "n_batch": 512,
        "target_vram": "6-8 GB"
    }
}
```

**M√©triques √† mesurer :**
```python
# Pour chaque profil :
- VRAM usage (MB)
- VRAM peak (MB)
- Latency (ms)
- Throughput (tok/s)
- Stability (crashs, OOM errors)
```

#### 3. Impl√©menter S√©lection Dynamique

**Fichier :** `src/ai/config.py`

**Changement :**
```python
from src.utils.gpu_monitor import suggest_profile

profile = suggest_profile()
config = GPU_PROFILES[profile]

LlamaModelConfig(
    n_gpu_layers=config["n_gpu_layers"],
    n_batch=config["n_batch"],
    # ...
)
```

### R√©sultats Attendus

**Pas de gain de vitesse, mais :**
- ‚úÖ **Pr√©vention des crashs** (stabilit√© maximale)
- ‚úÖ **Monitoring temps r√©el** (alertes si VRAM critique)
- ‚úÖ **Adaptation automatique** au GPU disponible

---

## üîú Phase 6 : Tests & Documentation Finale (Apr√®s Phase 5)

### Objectif
Valider TOUTES les optimisations cumul√©es et documenter les r√©sultats globaux.

### Plan d'Impl√©mentation

#### 1. Cr√©er `tests/test_integration_performance.py`

**Objectif :** Test d'int√©gration complet validant toutes les phases.

**Tests √† impl√©menter :**
```python
def test_memory_no_leaks():
    """Valide Phase 1 : Aucune fuite m√©moire."""

def test_llm_cache_warming():
    """Valide Phase 2 : Cache warming actif."""

def test_ipc_batching():
    """Valide Phase 3 : Batching disponible."""

def test_cpu_auto_detection():
    """Valide Phase 4 : CPU d√©tect√© correctement."""

def test_gpu_monitoring():
    """Valide Phase 5 : GPU monitoring actif."""

def test_overall_performance():
    """Mesure performance globale vs baseline initiale."""
```

#### 2. Benchmark Final Global

**Script :** `scripts/benchmark_final.py`

**Objectif :** Comparer performance AVANT vs APR√àS Session 11.

**M√©triques globales :**
```python
# Baseline Chat 9 (AVANT Session 11)
- Load time : ~5.10s
- First generation : 2.11s (19.46 tok/s)
- IPC latency : 0.40 ms (estimation)
- Memory leaks : Non test√©

# After Session 11 (APR√àS Phases 1-6)
- Load time : ~2.57s (-49.6%)
- First generation : 1.75s (-17%)
- IPC latency : 0.06 ms (-85%)
- Memory leaks : ‚úÖ Aucune
- CPU optimization : ‚úÖ Auto
- GPU monitoring : ‚úÖ Actif

TOTAL GAIN : +30-40% performance globale + Stabilit√© maximale
```

#### 3. Documentation Compl√®te

**Fichiers √† cr√©er :**

1. **`docs/sessions/session_11_performance/README.md`**
   - Vue d'ensemble des 6 phases
   - Liens vers chaque guide d√©taill√©
   - R√©sultats globaux

2. **`docs/sessions/session_11_performance/FINAL_RESULTS.md`**
   - Benchmark final complet
   - Graphiques de performance
   - Comparaison AVANT/APR√àS
   - Recommandations futures

**‚ö†Ô∏è NE PAS OUBLIER :**
- ‚úÖ Mettre √† jour `README.md` racine (Changelog, Status)
- ‚úÖ Mettre √† jour `docs/INDEX.md`
- ‚úÖ Mettre √† jour `docs/README.md`
- ‚úÖ Archiver TOUS les scripts dans `docs/session_11_performance/scripts/`

---

## üö® Points d'Attention Critiques

### 1. VRAM Limit√©e (RTX 4050 6GB)
```
‚ö†Ô∏è Actuellement : 6012 MB / 6144 MB (98%)
‚ö†Ô∏è Marge : 132 MB (2%)
üéØ Phase 5 : Impl√©menter monitoring + alertes
```

### 2. CPU Threads Hardcod√©s
```
‚ö†Ô∏è Actuellement : n_threads=6 fixe
üéØ Phase 4 : Remplacer par auto-d√©tection
```

### 3. Pas de Tests d'Int√©gration
```
‚ö†Ô∏è Actuellement : Tests unitaires uniquement
üéØ Phase 6 : Cr√©er suite de tests compl√®te
```

### 4. Documentation README Racine
```
‚ö†Ô∏è L'utilisateur a d√©j√† d√ª rappeler cette r√®gle
üö® JAMAIS oublier de mettre √† jour les 4 sections !
```

---

## üõ†Ô∏è Commandes Utiles

### Activation Environnement (OBLIGATOIRE)
```powershell
# TOUJOURS avant toute commande Python !
venv\Scripts\Activate.ps1

# V√©rification
python --version  # Doit afficher : Python 3.10.9
```

### Tests
```powershell
# Tests unitaires
pytest tests/

# Tests avec couverture
pytest --cov=src tests/

# Test sp√©cifique
pytest tests/test_integration_performance.py
```

### Benchmarks
```powershell
# Phase 4 : CPU
python scripts/benchmark_cpu_threads.py

# Phase 5 : GPU
python scripts/benchmark_gpu_profiles.py

# Phase 6 : Final
python scripts/benchmark_final.py
```

### Git
```powershell
# Voir les fichiers modifi√©s
git status

# Commit avec Conventional Commits
git add .
git commit -m "feat: add CPU auto-detection (Session 11 Phase 4)"

# Push
git push origin main
```

---

## üìä Objectif Final Session 11

**Am√©liorer les performances globales de +30-40%** üöÄ

**Progress :**
- ‚úÖ Phase 1 : Stabilit√© m√©moire (aucune fuite)
- ‚úÖ Phase 2 : -17% latency LLM
- ‚úÖ Phase 3 : +907% throughput IPC
- üéØ Phase 4 : +5-15% CPU
- üéØ Phase 5 : Stabilit√© GPU
- üéØ Phase 6 : Validation globale

**Cumul attendu : +30-40% + Stabilit√© maximale** ‚ú®

---

## ‚úÖ Checklist Finale (Avant de Terminer Session 11)

```
‚ñ° Phase 4 : CPU Optimization TERMIN√âE
   ‚îî‚îÄ‚îÄ Scripts : cpu_detection.py, benchmark_cpu_threads.py
   ‚îî‚îÄ‚îÄ Doc : CPU_OPTIMIZATION.md
   ‚îî‚îÄ‚îÄ Tests : pytest OK

‚ñ° Phase 5 : GPU Profiling TERMIN√âE
   ‚îî‚îÄ‚îÄ Scripts : gpu_monitor.py, benchmark_gpu_profiles.py
   ‚îî‚îÄ‚îÄ Doc : GPU_PROFILING.md
   ‚îî‚îÄ‚îÄ Tests : pytest OK

‚ñ° Phase 6 : Tests & Docs TERMIN√âE
   ‚îî‚îÄ‚îÄ Tests : test_integration_performance.py
   ‚îî‚îÄ‚îÄ Benchmark : benchmark_final.py
   ‚îî‚îÄ‚îÄ Docs : README.md, FINAL_RESULTS.md

‚ñ° Documentation COMPL√àTE
   ‚îî‚îÄ‚îÄ README.md racine (4 sections !)
   ‚îî‚îÄ‚îÄ docs/INDEX.md
   ‚îî‚îÄ‚îÄ docs/README.md
   ‚îî‚îÄ‚îÄ Session 11 README.md (vue d'ensemble)

‚ñ° Scripts archiv√©s
   ‚îî‚îÄ‚îÄ Tous dans docs/session_11_performance/scripts/

‚ñ° Git commit
   ‚îî‚îÄ‚îÄ Conventional Commits pour chaque phase
```

---

## üéì Conclusion pour Chat 11

Tu vas compl√©ter la **Session 11 Performance Optimizations** en impl√©mentant les **Phases 4, 5 et 6**.

**Priorit√©s :**
1. üéØ **Phase 4** : CPU Optimization (commence ici !)
2. üéØ **Phase 5** : GPU Profiling & Tuning
3. üéØ **Phase 6** : Tests & Documentation Finale

**R√®gles d'or :**
- ‚úÖ Toujours expliquer clairement (utilisateur non-expert)
- ‚úÖ Demander confirmation avant changements majeurs
- ‚úÖ **JAMAIS** oublier la documentation (README racine 4 sections !)
- ‚úÖ Archiver scripts dans `docs/session_11_performance/scripts/`
- ‚úÖ Tests unitaires apr√®s chaque phase

**Objectif :** +30-40% performance globale + Stabilit√© maximale üöÄ

---

**üé≠ Bon courage pour la Session 11 Chat 11 ! Tu vas g√©rer comme un pro ! ‚ú®**
